{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6087dede",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PosixPath('.')"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from models.common import DetectMultiBackend\n",
        "from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadScreenshots, LoadStreams\n",
        "from utils.general import (LOGGER, Profile, check_file, check_img_size, check_imshow, check_requirements, colorstr, cv2,\n",
        "                           increment_path, non_max_suppression, print_args, scale_boxes, strip_optimizer, xyxy2xywh)\n",
        "from utils.plots import Annotator, colors, save_one_box\n",
        "from utils.torch_utils import select_device, smart_inference_mode\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "import platform\n",
        "import sys\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "FILE = Path('.').resolve()\n",
        "ROOT = FILE.parents[0]  # YOLOv5 root directory\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.append(str(ROOT))\n",
        "\n",
        "ROOT = Path(os.path.relpath('.', Path.cwd())) \n",
        "ROOT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16b1449e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import sys\n",
        "# import optparse\n",
        "\n",
        "# parser = optparse.OptionParser()\n",
        "\n",
        "# parser.add_option('-p', '--path', help='Pass the path image',default = '.')\n",
        "\n",
        "# (opts, args) = parser.parse_args()  # instantiate parser\n",
        "\n",
        "# imgPath = opts.path\n",
        "\n",
        "\n",
        "# print(imgPath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "04355fcb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# param\n",
        "weights = 'pretrain_model/yolov5x6[exp]_on_all_yolo_dataset/weights/best.pt'\n",
        "# \n",
        "data=f'{ROOT}/data/coco128.yaml'  # dataset.yaml path\n",
        "imgsz=(640, 640) # inference size (height, width)\n",
        "conf_thres=0.50  # confidence threshold\n",
        "iou_thres=0.45  # NMS IOU threshold\n",
        "max_det=1000 # maximum detections per image\n",
        "device='cpu'  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
        "view_img=False  # show results\n",
        "save_txt=False  # save results to *.txt\n",
        "save_conf=False  # save confidences in --save-txt labels\n",
        "save_crop=False  # save cropped prediction boxes\n",
        "nosave=False  # do not save images/videos\n",
        "classes=None # filter by class: --class 0, or --class 0 2 3\n",
        "agnostic_nms=False  # class-agnostic NMS\n",
        "augment=False # augmented inference\n",
        "visualize=False # visualize features\n",
        "update=False  # update all models\n",
        "project=f'{ROOT}/runs/detect'  # save results to project/name\n",
        "name='exp',  # save results to project/name\n",
        "exist_ok=False  # existing project/name ok, do not increment\n",
        "line_thickness=3  # bounding box thickness (pixels)\n",
        "hide_labels=False  # hide labels\n",
        "hide_conf=False  # hide confidences\n",
        "half=False  # use FP16 half-precision inference\n",
        "dnn=False  # use OpenCV DNN for ONNX inference\n",
        "vid_stride=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "aede9244",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fusing layers... \n",
            "Model summary: 416 layers, 140057380 parameters, 0 gradients, 208.1 GFLOPs\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "83352cc3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "14478dc4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# img ='/home/uwu/Desktop/object_detection/preview/sketch_web_ui_dataset/all_yolo/images/16483b6e-47fe-4e9c-b78c-7f0ba4fef80c.png'\n",
        "\n",
        "\n",
        "img ='/home/uwu/Desktop/object_detection/preview/sketch_web_ui_dataset/new_dataset/80ce0ae6-9f89-429b-b2da-ae1b25e45acb.png'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e5eca81f",
      "metadata": {
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5 ðŸš€ 2023-5-12 Python-3.10.10 torch-1.13.1+cu117 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 416 layers, 140057380 parameters, 0 gradients, 208.1 GFLOPs\n"
          ]
        }
      ],
      "source": [
        "source = str(img)\n",
        "save_img = not nosave and not source.endswith('.txt')  # save inference images\n",
        "is_file = Path(source).suffix[1:] in (IMG_FORMATS + VID_FORMATS)\n",
        "is_url = source.lower().startswith(('rtsp://', 'rtmp://', 'http://', 'https://'))\n",
        "\n",
        "if is_url and is_file:\n",
        "    source = check_file(source)  # download\n",
        "\n",
        "# Directories\n",
        "save_dir = '.'  # make dir\n",
        "\n",
        "# Load model\n",
        "device = select_device(device)\n",
        "model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
        "stride, names, pt = model.stride, model.names, model.pt\n",
        "imgsz = check_img_size(imgsz, s=stride)  # check image size\n",
        "\n",
        "# Dataloader\n",
        "bs = 1 \n",
        "stride, names, pt = model.stride, model.names, model.pt\n",
        "\n",
        "\n",
        "dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3273876c",
      "metadata": {},
      "outputs": [],
      "source": [
        "model.warmup(imgsz=(1 if pt or model.triton else bs, 3, *imgsz))  # warmup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "842681ff",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# preduct\n",
        "\n",
        "seen, windows, dt = 0, [], (Profile(), Profile(), Profile())\n",
        "\n",
        "for path, im, im0s, vid_cap, s in dataset:\n",
        "    with dt[0]:\n",
        "        im = torch.from_numpy(im).to(model.device)\n",
        "        im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32\n",
        "        im /= 255  # 0 - 255 to 0.0 - 1.0\n",
        "        if len(im.shape) == 3:\n",
        "            im = im[None]  # expand for batch dim\n",
        "\n",
        "    # Inference\n",
        "    with dt[1]:\n",
        "        visualize = increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False\n",
        "        pred = model(im, augment=augment, visualize=visualize)\n",
        "\n",
        "    # NMS\n",
        "    with dt[2]:\n",
        "        pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "#process pred to df\n",
        "det = pred[0]\n",
        "pred_df = pd.DataFrame(columns=['class','xmin','ymin','xmax','ymax','conf'])\n",
        "\n",
        "p, im0, frame = path, im0s.copy(), getattr(dataset, 'frame', 0)\n",
        "p = Path(p)  # to Path\n",
        "gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
        "imc = im0.copy() if save_crop else im0  # for save_crop\n",
        "annotator = Annotator(im0, line_width=line_thickness, example=str(names))\n",
        "if len(det):\n",
        "    # Rescale boxes from img_size to im0 size\n",
        "    det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0.shape).round()\n",
        "\n",
        "\n",
        "for *xyxy, conf, cls in reversed(det):   \n",
        "    xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
        "\n",
        "    # Add bbox to image\n",
        "    clsInt = int(cls)  # integer class\n",
        "    label = None if hide_labels else (names[c] if hide_conf else f'{names[clsInt]} {conf:.2f}')\n",
        "\n",
        "    annotator.box_label(xyxy, label, color=colors(clsInt, True))\n",
        "    \n",
        "    row= [\n",
        "        names[clsInt],\n",
        "        int(xyxy[0]),\n",
        "        int(xyxy[1]),\n",
        "        int(xyxy[2]),\n",
        "        int(xyxy[3]),\n",
        "        float(f'{conf:.2f}')\n",
        "    ]\n",
        "    pred_df.loc[len(pred_df)+1] = row \n",
        "#     print(\"xywh:\",xywh)\n",
        "#     print(\"xyxy:\",int(xyxy[0]))\n",
        "#     print(\"xyxy:\",xyxy)\n",
        "#     print('cls:',cls)\n",
        "#     print('conf:',conf)\n",
        "#     print('label:',label) \n",
        "#     print('row:',row) \n",
        "#     print('\\n')\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "pred_img = annotator.result()\n",
        "\n",
        "cv2.imwrite('../predicted/1.jpg', pred_img)\n",
        "\n",
        "# cv2.imshow('result', pred_img)\n",
        "# cv2.waitKey(0)\n",
        "# cv2.destroyAllWindows()\n",
        "# print(pred_img)\n",
        "# print(im0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b11f98ca",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "      <th>conf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CheckBox</td>\n",
              "      <td>601</td>\n",
              "      <td>520</td>\n",
              "      <td>640</td>\n",
              "      <td>603</td>\n",
              "      <td>0.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Label</td>\n",
              "      <td>177</td>\n",
              "      <td>275</td>\n",
              "      <td>265</td>\n",
              "      <td>305</td>\n",
              "      <td>0.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Label</td>\n",
              "      <td>39</td>\n",
              "      <td>266</td>\n",
              "      <td>119</td>\n",
              "      <td>291</td>\n",
              "      <td>0.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CheckBox</td>\n",
              "      <td>29</td>\n",
              "      <td>38</td>\n",
              "      <td>207</td>\n",
              "      <td>98</td>\n",
              "      <td>0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Label</td>\n",
              "      <td>169</td>\n",
              "      <td>361</td>\n",
              "      <td>254</td>\n",
              "      <td>392</td>\n",
              "      <td>0.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>TextBox</td>\n",
              "      <td>382</td>\n",
              "      <td>56</td>\n",
              "      <td>505</td>\n",
              "      <td>101</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Button</td>\n",
              "      <td>506</td>\n",
              "      <td>61</td>\n",
              "      <td>582</td>\n",
              "      <td>112</td>\n",
              "      <td>0.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Paragraph</td>\n",
              "      <td>174</td>\n",
              "      <td>306</td>\n",
              "      <td>257</td>\n",
              "      <td>358</td>\n",
              "      <td>0.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Button</td>\n",
              "      <td>20</td>\n",
              "      <td>382</td>\n",
              "      <td>127</td>\n",
              "      <td>433</td>\n",
              "      <td>0.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Button</td>\n",
              "      <td>297</td>\n",
              "      <td>402</td>\n",
              "      <td>422</td>\n",
              "      <td>455</td>\n",
              "      <td>0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Paragraph</td>\n",
              "      <td>38</td>\n",
              "      <td>292</td>\n",
              "      <td>111</td>\n",
              "      <td>342</td>\n",
              "      <td>0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Paragraph</td>\n",
              "      <td>312</td>\n",
              "      <td>318</td>\n",
              "      <td>403</td>\n",
              "      <td>373</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Button</td>\n",
              "      <td>156</td>\n",
              "      <td>391</td>\n",
              "      <td>274</td>\n",
              "      <td>447</td>\n",
              "      <td>0.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Image</td>\n",
              "      <td>36</td>\n",
              "      <td>123</td>\n",
              "      <td>120</td>\n",
              "      <td>264</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Image</td>\n",
              "      <td>321</td>\n",
              "      <td>129</td>\n",
              "      <td>420</td>\n",
              "      <td>290</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Image</td>\n",
              "      <td>177</td>\n",
              "      <td>125</td>\n",
              "      <td>269</td>\n",
              "      <td>276</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        class  xmin  ymin  xmax  ymax  conf\n",
              "1    CheckBox   601   520   640   603  0.52\n",
              "2       Label   177   275   265   305  0.55\n",
              "3       Label    39   266   119   291  0.56\n",
              "4    CheckBox    29    38   207    98  0.57\n",
              "5       Label   169   361   254   392  0.58\n",
              "6     TextBox   382    56   505   101  0.76\n",
              "7      Button   506    61   582   112  0.88\n",
              "8   Paragraph   174   306   257   358  0.89\n",
              "9      Button    20   382   127   433  0.89\n",
              "10     Button   297   402   422   455  0.91\n",
              "11  Paragraph    38   292   111   342  0.91\n",
              "12  Paragraph   312   318   403   373  0.92\n",
              "13     Button   156   391   274   447  0.93\n",
              "14      Image    36   123   120   264  0.95\n",
              "15      Image   321   129   420   290  0.96\n",
              "16      Image   177   125   269   276  0.96"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "ef91ae1f",
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_df.to_csv('../predicted/DSL.csv')\n",
        "pred_df=pred_df.sort_values(by=['xmin'], ascending=[True])\n",
        "pred_df=pred_df.sort_values(by=['ymin'], ascending=[True])\n",
        "column=pred_df['class']\n",
        "my_list = pred_df[\"class\"].tolist()\n",
        "with open(r\"../predicted/DSL.txt\",\"w\") as File_object:\n",
        "    # File_object.write(\"{\\n\")\n",
        "    for item in my_list:\n",
        "        item +=  ','+'\\n' \n",
        "        File_object.write(item)\n",
        "        \n",
        "    # File_object.write(\"}\")\n",
        "        \n",
        "        \n",
        "File_object.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "14d51f92",
      "metadata": {},
      "outputs": [],
      "source": [
        "os.system('cd ../compiler/compiler_pix2code/ && python3 web-compiler.py ../../predicted/DSL.txt ../../predicted/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14a6d946",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
